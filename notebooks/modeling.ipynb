{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7984d63-91d5-448b-b034-b571fdc5f6b9",
   "metadata": {},
   "source": [
    "# Моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511b963-b2c5-4d80-bee3-70150d54d01e",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456c7dde-880e-41f8-8636-f250ea6f69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191385b2-d801-4a9d-b395-d7479ba10fca",
   "metadata": {},
   "source": [
    "## Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5557fee8-2202-4dae-b5a5-689db75b16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "SOURCE_PATH = os.path.join(DATA_DIR, \"cleaned_data.csv\")\n",
    "\n",
    "data = pd.read_csv(SOURCE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ac3c5c-c6f5-4142-89b6-4fbbee476f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>2009-04-06 22:19:45</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>awww thats a bummer you shoulda got david carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>2009-04-06 22:19:49</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>2009-04-06 22:19:53</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>2009-04-06 22:19:57</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>2009-04-06 22:19:57</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>no its not behaving at all im mad why am i her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                 date             user  \\\n",
       "0       0  1467810369  2009-04-06 22:19:45  _TheSpecialOne_   \n",
       "1       0  1467810672  2009-04-06 22:19:49    scotthamilton   \n",
       "2       0  1467810917  2009-04-06 22:19:53         mattycus   \n",
       "3       0  1467811184  2009-04-06 22:19:57          ElleCTF   \n",
       "4       0  1467811193  2009-04-06 22:19:57           Karoli   \n",
       "\n",
       "                                                text  \n",
       "0  awww thats a bummer you shoulda got david carr...  \n",
       "1  is upset that he cant update his facebook by t...  \n",
       "2  i dived many times for the ball managed to sav...  \n",
       "3     my whole body feels itchy and like its on fire  \n",
       "4  no its not behaving at all im mad why am i her...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42116548-6783-448a-bfb7-09b9deea53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Обучить на всей выборке\n",
    "data = data.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959a8f4a-3596-4edf-a8b9-86487b695ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем данные на тренировочную и тестовую выборки\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split( \\\n",
    "    data['text'].tolist(), data['target'].tolist(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70151488-0d7c-4d6b-8fdb-7f9982e0f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизируем данные\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73491dc-6f54-4505-87d0-ff095ee82f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем вспомогательный класс для BERT-модели\n",
    "class Sentiment140Dataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dff5c33-bbbb-43e2-9fbc-e0098e6145a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Sentiment140Dataset(train_encodings, train_labels)\n",
    "val_dataset = Sentiment140Dataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1a35e9-1dc5-4c1a-92ca-1296624efe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Загружаем модель\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "542eeb1a-d4d3-4def-a2fd-ade3569919ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем тренировочный пайплайн\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0847afa-6e41-43df-9715-840eea349fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed\n",
      "Epoch 2 completed\n",
      "Epoch 3 completed\n"
     ]
    }
   ],
   "source": [
    "# Цикл обучения\n",
    "n_epoch = 3\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14fdf6f5-dcf0-4087-914c-b788fc9aa608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцениваем модель\n",
    "model.eval()\n",
    "preds, true_labels = [], []\n",
    "\n",
    "for batch in val_loader:\n",
    "    inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    preds.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "    true_labels.extend(inputs['labels'].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86eccdbf-f842-4f99-b573-55b99828c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7875\n"
     ]
    }
   ],
   "source": [
    "# Расчитываем Accuracy\n",
    "accuracy = accuracy_score(true_labels, preds)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a828a5d7-67f8-45fc-9557-9a3eb0c93b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/tokenizer_config.json',\n",
       " '../models/special_tokens_map.json',\n",
       " '../models/vocab.txt',\n",
       " '../models/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраняем модель и токенизатор\n",
    "MODEL_DIR = \"../models\"\n",
    "\n",
    "model.save_pretrained(MODEL_DIR)\n",
    "tokenizer.save_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99cea98a-f1b5-470c-8f95-a348ce166187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказываем тональнось текста\n",
    "def predict_sentiment(text):\n",
    "    # Токенизируем входной текст\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    # Выполняем предсказание\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Получаем предсказание\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    label_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "    return label_map[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78989d27-fc11-44f7-b4b9-4e6a5d5bb359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Fuck reading and anyone who can do it -> Sentiment: Positive\n",
      "Text: Kamala seems like a very nice human  I just wanna say sorry to her kids -> Sentiment: Negative\n",
      "Text: Trumps back in office. Ye’s back a billionaire. The world might just be ok -> Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Fuck reading and anyone who can do it\"\n",
    "text2 = \"Kamala seems like a very nice human  I just wanna say sorry to her kids\"\n",
    "text3 = \"Trumps back in office. Ye’s back a billionaire. The world might just be ok\"\n",
    "\n",
    "print(f\"Text: {text1} -> Sentiment: {predict_sentiment(text1)}\")\n",
    "print(f\"Text: {text2} -> Sentiment: {predict_sentiment(text2)}\")\n",
    "print(f\"Text: {text3} -> Sentiment: {predict_sentiment(text3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
